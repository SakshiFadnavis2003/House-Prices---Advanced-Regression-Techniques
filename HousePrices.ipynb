{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.4.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\tusha\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tusha\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.4.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3092\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3108\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3103\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3120\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3108\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.021897\n",
      "Cross-validation RMSE: 0.13310902739454394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3374\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 12.024057\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "# Handle missing values\n",
    "# Example: filling missing numeric values with mean and categorical with mode\n",
    "numeric_cols = all_data.select_dtypes(include=np.number).columns\n",
    "categorical_cols = all_data.select_dtypes(include='object').columns\n",
    "\n",
    "all_data[numeric_cols] = all_data[numeric_cols].fillna(all_data[numeric_cols].mean())\n",
    "all_data[categorical_cols] = all_data[categorical_cols].fillna(all_data[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_data[col] = le.fit_transform(all_data[col])\n",
    "\n",
    "# Log-transform the target variable (SalePrice)\n",
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "\n",
    "# Split back into train and test sets\n",
    "train_processed = all_data.iloc[:train.shape[0], :]\n",
    "test_processed = all_data.iloc[train.shape[0]:, :]\n",
    "\n",
    "# Define features and target\n",
    "X = train_processed.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = train['SalePrice']\n",
    "\n",
    "# Model training and evaluation\n",
    "\n",
    "# Initialize LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Cross-validation on the training set\n",
    "cv_scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f'Cross-validation RMSE: {-cv_scores.mean()}')\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "\n",
    "# Prepare test data for prediction\n",
    "test_ids = test['Id']\n",
    "X_test = test_processed.drop(['Id', 'SalePrice'], axis=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = np.expm1(model.predict(X_test))  # Reverse log transformation\n",
    "\n",
    "# Prepare submission file\n",
    "submission = pd.DataFrame({'Id': test_ids, 'SalePrice': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
